import streamlit as st
import pandas as pd
import plotly.express as px
import torch
import librosa
from PIL import Image
from transformers import Wav2Vec2Processor, Wav2Vec2ForSequenceClassification
import numpy as np



# Fonction pour pr√©dire le sentiment √† partir d'un fichier audio
def predict_sentiment_v2(audio_path, model_path, processor_path, inverse_label_map, max_length=32000, device='cuda' if torch.cuda.is_available() else 'cpu'):
    """
    Pr√©dit le sentiment d'un fichier audio donn√©.
    
    Args:
        audio_path (str): Chemin vers le fichier audio √† analyser.
        model_path (str): Chemin vers le mod√®le sauvegard√©.
        processor_path (str): Chemin vers le processeur Wav2Vec2 sauvegard√©.
        inverse_label_map (dict): Dictionnaire pour mapper les indices √† des labels lisibles.
        max_length (int): Longueur maximale des √©chantillons audio (en points).
        device (str): Device √† utiliser pour l'inf√©rence ('cuda' ou 'cpu').

    Returns:
        str: Le sentiment pr√©dit (label).
    """
    # Charger le mod√®le et le processeur
    model = Wav2Vec2ForSequenceClassification.from_pretrained(model_path).to(device)
    processor = Wav2Vec2Processor.from_pretrained(processor_path)
    
    # Charger l'audio et le pr√©traiter
    speech, sr = librosa.load(audio_path, sr=16000)  # Charger l'audio avec une fr√©quence d'√©chantillonnage de 16 kHz
    if len(speech) > max_length:
        speech = speech[:max_length]
    else:
        speech = np.pad(speech, (0, max_length - len(speech)), 'constant')
    
    # Transformer l'audio en entr√©e pour le mod√®le
    inputs = processor(speech, sampling_rate=16000, return_tensors='pt', padding=True, truncation=True, max_length=max_length)
    input_values = inputs.input_values
    
    # Pr√©diction
    model.eval()
    with torch.no_grad():
        outputs = model(input_values)
        logits = outputs.logits
    
    # Obtenir la classe pr√©dite
    predicted_class = logits.argmax(dim=-1).item()
    predicted_label = inverse_label_map[predicted_class]
    
    return predicted_label


# Fonction d'analyse exploratoire
def exploratory_analysis(df):
    st.subheader("üîç Analyse exploratoire des donn√©es")
    st.write("Statistiques descriptives des donn√©es :")
    st.write(df.describe(include='all'))

    emotion_counts = df['Emotion'].value_counts()
    fig_emotion = px.pie(values=emotion_counts, names=emotion_counts.index, title="R√©partition des √©motions", color_discrete_sequence=px.colors.qualitative.Set3)
    st.plotly_chart(fig_emotion, use_container_width=True)

    intensity_counts = df['Emotion intensity'].value_counts()
    fig_intensity = px.bar(x=intensity_counts.index, y=intensity_counts.values, title="Intensit√© des √©motions", labels={'x': 'Intensit√©', 'y': 'Nombre'}, color=intensity_counts.index, color_discrete_sequence=px.colors.qualitative.Pastel)
    st.plotly_chart(fig_intensity, use_container_width=True)

    gender_counts = df['Gender'].value_counts()
    fig_gender = px.bar(x=gender_counts.index, y=gender_counts.values, title="R√©partition des genres", labels={'x': 'Genre', 'y': 'Nombre'}, color=gender_counts.index, color_discrete_sequence=px.colors.qualitative.Prism)
    st.plotly_chart(fig_gender, use_container_width=True)

    fig_emotion_intensity = px.histogram(df, x='Emotion', color='Emotion intensity', barmode='group', title="R√©partition des √©motions par intensit√©", color_discrete_sequence=px.colors.qualitative.Set2)
    st.plotly_chart(fig_emotion_intensity, use_container_width=True)

    fig_emotion_gender = px.histogram(df, x='Emotion', color='Gender', barmode='group', title="R√©partition des √©motions par genre", color_discrete_sequence=px.colors.qualitative.Dark2)
    st.plotly_chart(fig_emotion_gender, use_container_width=True)

    reduced_emotion_counts = df['Emotion_Category'].value_counts().sort_index()
    fig_reduced_emotion = px.pie(values=reduced_emotion_counts, names=reduced_emotion_counts.index, title="R√©partition des √©motions r√©duites", color_discrete_sequence=px.colors.qualitative.Vivid)
    st.plotly_chart(fig_reduced_emotion, use_container_width=True)

    fig_reduced_emotion_gender = px.histogram(df, x='Emotion_Category', color='Gender', barmode='group', title="R√©partition des √©motions r√©duites par genre", color_discrete_sequence=px.colors.qualitative.Safe)
    st.plotly_chart(fig_reduced_emotion_gender, use_container_width=True)

    st.write("Exemples de donn√©es :")
    st.dataframe(df.sample(5))

# Fonction principale pour afficher le dashboard
def main():
    st.set_page_config(page_title="Dashboard d'Analyse de Sentiment Audio", layout="wide")
    left_co, cent_co, last_co = st.columns(3)
    with cent_co:
        st.image("images/banner.jpg", width=400)

    st.sidebar.title("Options du Dashboard")
    st.sidebar.write("Utilisez cette barre pour naviguer dans les options.")
    
    # Charger les donn√©es fictives
    df = pd.read_csv('ravdess_streamlit.csv')
    df_audio = df.head(43)

    # Charger le mod√®le et le processeur pour les pr√©dictions
    model_path = "./model_and_processor"  # Remplacez par le chemin de votre mod√®le
    processor_path  = "./model_and_processor"    
    inverse_label_map = {0: 'neutral', 1: 'positif', 2: 'positif', 3: 'negatif', 4: 'negatif', 5: 'negatif'}  # Remplacez par votre map
    #inverse_label_map_audio = {'neutral': 0, 'calm': 'positif', 'happy': 'positif', 'sad': "negatif", 'angry': "negatif", 'fear': "negatif"}  # Remplacez par votre map

    # Afficher un widget pour s√©lectionner l'analyse ou la pr√©diction
    option = st.sidebar.selectbox("Choisissez une option :", ["Analyse exploratoire", "Pr√©diction de sentiment", "Pr√©dire sentiment sur fichier audio"])

    if option == "Analyse exploratoire":
        exploratory_analysis(df)

    elif option == "Pr√©diction de sentiment":
        st.subheader("üéß Pr√©diction du sentiment pour un fichier audio")
        audio_id = st.sidebar.selectbox("Choisir un ID audio :", df_audio['Path'].unique())
        #print(f"audio_id est::::::::::{audio_id}")
        #print(f"type de audio_id st::::::::::{type(audio_id)}")
        #audio_id = audio_id.replace("/", "\\")
        #print(f"nouveau audio_id est::::::::::{audio_id}")
        audio_info = df[df['Path'] == audio_id].iloc[0]

        st.write("### Informations sur l'audio s√©lectionn√© :")
        st.write(f"- **Genre :** {audio_info['Gender']}")
        st.write(f"- **Emotion r√©elle :** {audio_info['Emotion_Category']}")

        if st.button("Pr√©dire le sentiment"):
            sentiment = predict_sentiment_v2(audio_id, model_path, processor_path, inverse_label_map)
            st.write(f"### Le sentiment pr√©dit pour cet audio est : **{sentiment}**")
            # Afficher une image de sentiment si la pr√©diction est effectu√©e
            if sentiment:
                # Charger les images locales pour chaque sentiment
                sentiment_images = {
                    "positif": Image.open("images/positif.jpg"),
                    "neutral": Image.open("images/neutre.jpg"),
                    "negatif": Image.open("images/negatif.jpg")
                }
                st.image(sentiment_images[sentiment], width=150, caption=f"Sentiment : {sentiment}")


    elif option == "Pr√©dire sentiment sur fichier audio":
        st.subheader("üé§ Pr√©diction de sentiment pour un fichier audio upload√©")
        audio_file = st.file_uploader("T√©l√©chargez un fichier audio", type=["wav", "mp3"])

        if audio_file is not None:
            with open("uploaded_audio.wav", "wb") as f:
                f.write(audio_file.getbuffer())
            st.audio(audio_file, format="audio/wav")

            if st.button("Pr√©dire le sentiment"):
                sentiment = predict_sentiment_v2("uploaded_audio.wav", model_path, processor_path, inverse_label_map)
                st.write(f"### Le sentiment pr√©dit pour cet audio est : **{sentiment}**")
                # Afficher une image de sentiment si la pr√©diction est effectu√©e
                if sentiment:
                    # Charger les images locales pour chaque sentiment
                    sentiment_images = {
                        "positif": Image.open("images/positif.jpg"),
                        "neutral": Image.open("images/neutre.jpg"),
                        "negatif": Image.open("images/negatif.jpg")
                    }
                    st.image(sentiment_images[sentiment], width=150, caption=f"Sentiment : {sentiment}")


if __name__ == "__main__":
    main()
